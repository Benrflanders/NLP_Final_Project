{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a file to analyze the pre processed enron email data. DOES NOT DO ANY EDITING OF EMAIL DATA\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus.reader import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_dir = os.path.expanduser('~/finalProject/enron_data_processed/')\n",
    "corpus_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "1_1.txt\n",
      "1_2.txt\n",
      "1_4.txt\n",
      "1_5.txt\n",
      "2_1.txt\n",
      "2_2.txt\n",
      "2_4.txt\n",
      "2_5.txt\n",
      "3_2.txt\n",
      "3_5.txt\n",
      "4_1.txt\n",
      "4_2.txt\n",
      "4_4.txt\n",
      "4_5.txt\n",
      "5_1.txt\n",
      "5_2.txt\n",
      "5_3.txt\n",
      "5_4.txt\n",
      "5_5.txt\n"
     ]
    }
   ],
   "source": [
    "relationship_list = os.listdir(corpus_dir)\n",
    "relationship_list_sorted = sorted(relationship_list)\n",
    "\n",
    "#print out each person in the list of people\n",
    "for relationship in relationship_list_sorted:\n",
    "    print(relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5_5.txt', '5_2.txt', '2_1.txt', '4_5.txt', '4_2.txt', '5_3.txt', '5_4.txt', '1_1.txt', '4_4.txt', '1_5.txt', '1_2.txt', '2_4.txt', '4_1.txt', '3_2.txt', '3_5.txt', '1_4.txt', '5_1.txt', '2_2.txt', '2_5.txt']\n"
     ]
    }
   ],
   "source": [
    "#create a dictionary that maps PlainTextReader to the text file name for\n",
    "#each relationship\n",
    "file_id_list = []\n",
    "\n",
    "for relation in os.listdir(corpus_dir):\n",
    "    if(os.path.isfile(os.path.join(corpus_dir, relation))):\n",
    "        tmp_corpus_file = os.path.join(corpus_dir, relation)\n",
    "        file_id_list.append(relation)\n",
    "        #newcorpus = PlaintextCorpusReader(tmp_corpus_file, '.*', encoding='latin-1')\n",
    "        #corpus_dict[relation] = newcorpus\n",
    "        #print(corpus_dict[relation])\n",
    "print(file_id_list)\n",
    "corpus = PlaintextCorpusReader(corpus_dir, file_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relationship : words\n",
      "5_5.txt  :  17501\n",
      "5_2.txt  :  3154\n",
      "2_1.txt  :  47993\n",
      "4_5.txt  :  8105\n",
      "4_2.txt  :  41590\n",
      "5_3.txt  :  1201\n",
      "5_4.txt  :  9424\n",
      "1_1.txt  :  40522\n",
      "4_4.txt  :  8575\n",
      "1_5.txt  :  2961\n",
      "1_2.txt  :  38640\n",
      "2_4.txt  :  14202\n",
      "4_1.txt  :  2975\n",
      "3_2.txt  :  2346\n",
      "3_5.txt  :  120\n",
      "1_4.txt  :  9608\n",
      "5_1.txt  :  11000\n",
      "2_2.txt  :  25473\n",
      "2_5.txt  :  16758\n"
     ]
    }
   ],
   "source": [
    "#corpus.__dir__()\n",
    "len(corpus.words()), [len(corpus.words(d)) for d in corpus.fileids()]\n",
    "print(\"relationship : words\")\n",
    "for d in corpus.fileids():\n",
    "    print(d, \" : \", len(corpus.words(d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "#get a frequency distribution for each label/relation and store that in a dict\n",
    "corpus_freq_dist_dict = {}\n",
    "for d in corpus.fileids():\n",
    "    wrds = list(corpus.words(d))\n",
    "    wrds = (w.lower().rstrip(punctuation) for w in wrds)\n",
    "    corpus_freq_dist_dict[d] = nltk.FreqDist(wrds)\n",
    "    \n",
    "    \n",
    "    #corpus_freq_dist_dict[key] = nltk.FreqDist(w.lower().rstrip(punctuation) for w in corpus_dict[key].words())\n",
    "    #print(key + \" : \")\n",
    "    #print(corpus_freq_dist_dict[key].most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'': 3225, 'the': 572, 'to': 460, 'you': 230, 'i': 225, 'and': 222, 'for': 220, 'is': 216, 'of': 204, 'will': 192, ...})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_freq_dist_dict['5_5.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from nltk.corpus import subjectivity\n",
    "subjectivity.__dir__()\n",
    "subj = subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
